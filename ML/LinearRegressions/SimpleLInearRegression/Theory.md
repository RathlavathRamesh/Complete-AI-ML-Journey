# SIMPLE LINEAR REGRESSION THEORETICAL CONCEPTS
- Simple Linear Regression is a statistical method that allows us to summarize and study relationships between two continuous (quantitative) variables.
- One variable, denoted x, is regarded as the predictor, explanatory, or independent variable.
- The other variable, denoted y, is regarded as the response, outcome, or dependent variable.
- The goal of simple linear regression is to model the relationship between the two variables by fitting a linear equation to observed data.
- The equation of a simple linear regression line is typically written as:
  y = β0 + β1*x + ε
  where:
  - y is the dependent variable (response)
  - x is the independent variable (predictor)
  - β0 is the y-intercept (the value of y when x = 0)
  - β1 is the slope of the line (the change in y for a one-unit change in x)
  - ε is the error term (the difference between the observed and predicted values of y)
- The parameters β0 and β1 are estimated from the data using methods such as Ordinary Least Squares (OLS), which minimizes the sum of the squared differences between the observed values and the values predicted by the linear model.

Our Aim is to minimize the Difference Between the Predicted Value and the True Values that is called the cost function 
